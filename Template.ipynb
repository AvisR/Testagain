{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install Required Library|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import blpapi\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "import blpapi\n",
    "import blpapi.event\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib.colors\n",
    "import dash\n",
    "from dash import dcc, html\n",
    "\n",
    "import seaborn as sns\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from plotly.offline import init_notebook_mode\n",
    "from plotly.graph_objs import Layout\n",
    "\n",
    "import pickle\n",
    "\n",
    "import os\n",
    "import warnings, gc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.20.0.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#SETTINGS FOR PLOTLY\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "init_notebook_mode(connected=True)\n",
    "temp = dict(layout=go.Layout(font=dict(family=\"Franklin Gothic\", size=12), width=800))\n",
    "colors=px.colors.qualitative.Plotly\n",
    "\n",
    "def configure_plotly_browser_state():\n",
    "  import IPython\n",
    "  display(IPython.core.display.HTML('''\n",
    "        <script src=\"/static/components/requirejs/require.js\"></script>\n",
    "        <script>\n",
    "          requirejs.config({\n",
    "            paths: {\n",
    "              base: '/static/base',\n",
    "              plotly: 'https://cdn.plot.ly/plotly-latest.min.js?noext',\n",
    "            },\n",
    "          });\n",
    "        </script>\n",
    "        '''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to import data from Bloomberg\n",
    "\n",
    "\n",
    "SECURITY_DATA = blpapi.Name('securityData')\n",
    "SECURITY = blpapi.Name('security')\n",
    "FIELD_DATA = blpapi.Name('fieldData')\n",
    "FIELD_EXCEPTIONS = blpapi.Name('fieldExceptions')\n",
    "FIELD_ID = blpapi.Name('fieldId')\n",
    "ERROR_INFO = blpapi.Name('errorInfo')\n",
    "\n",
    "class BLP():\n",
    "\n",
    "    def __init__(self):\n",
    "        #Bloomberg Session created only once here - makes consecutive bdp() and bdh() calls faster\n",
    "        self.session = blpapi.Session()\n",
    "        self.session.start()\n",
    "        self.refDataSvc = None\n",
    "        try:\n",
    "            self.session.openService('//BLP/refdata')\n",
    "            self.refDataSvc = self.session.getService('//BLP/refdata')\n",
    "        except:\n",
    "            print('Unable to open Service')\n",
    "\n",
    "    def terminate(self):\n",
    "        self.session.stop()\n",
    "\n",
    "    def bdp(self, securities, fields, OverrideFields = 'list',OverrideValues = 'list'):\n",
    "        '''\n",
    "        Emulate the BDP function found in the bloomberg addin for excel: Realtime Market data\n",
    "        securities: unique string identifying a unique security e.g. 'BABA US Equity' or a list of securities e.g.\n",
    "        ['BABA US Equity', 'AAPL US Equity']\n",
    "        field: unique string field identifier e.g. 'PX_LAST' or list of fields e.g.['PX_LAST','EQY_WEIGHTED_AVG_PX']\n",
    "        OverrideFields: list of overriding options for the field e.g. ['DVD_START_DT','DVD_END_DT']\n",
    "        OverrideValues: list of values associated to the OverrideFields param ['20140101','20140301']\n",
    "\n",
    "        returns a pandas dataframe\n",
    "\n",
    "        example:\n",
    "        BABA = blp.bdp('BABA US Equity','PX_LAST')\n",
    "        BABA = blp.bdp('BABA US Equity',['PX_LAST','EQY_WEIGHTED_AVG_PX'])\n",
    "        data = blp.bdp(['BABA US Equity', 'AAPL US Equity','SX5E Index'],['PX_LAST','EQY_WEIGHTED_AVG_PX'])\n",
    "\n",
    "        '''\n",
    "        if OverrideFields == 'list':\n",
    "            OverrideFields = []\n",
    "\n",
    "        if OverrideValues == 'list':\n",
    "            OverrideValues = []\n",
    "\n",
    "        if not self.refDataSvc:\n",
    "            return\n",
    "        request = self.refDataSvc.createRequest('ReferenceDataRequest')\n",
    "\n",
    "        if type(securities) == str:\n",
    "            securities = [securities]\n",
    "        for security in securities:\n",
    "            request.append('securities',security)\n",
    "\n",
    "        if type(fields) == str:\n",
    "            fields = [fields]\n",
    "        for strD in fields:\n",
    "            request.append('fields',strD)\n",
    "\n",
    "        if len(OverrideFields)!= 0 & (len(OverrideFields) == len(OverrideValues)):\n",
    "            for overrideField, overrideValue in zip(OverrideFields,OverrideValues):\n",
    "                o = request.getElement('overrides').appendElement()\n",
    "                o.setElement('fieldId','overrideField')\n",
    "                o.setElement('value',overrideValue)\n",
    "\n",
    "        requestID = self.session.sendRequest(request)\n",
    "        output = pd.DataFrame()\n",
    "\n",
    "        while True:\n",
    "            event = self.session.nextEvent()\n",
    "            for msg in event:\n",
    "                if requestID in msg.correlationIds():\n",
    "                    try:\n",
    "                        securityDataArray = msg.getElement(SECURITY_DATA)\n",
    "                        for securityData in getattr(securityDataArray ,'values')():\n",
    "                        #print securityData.getElementAsString(SECURITY)\n",
    "                            fieldData = securityData.getElement(FIELD_DATA)\n",
    "                            security = securityData.getElementAsString(SECURITY)\n",
    "                            eltDataFrame = pd.DataFrame(index = [security],columns = fields)\n",
    "                            for field in fieldData.elements():\n",
    "                                eltDataFrame.loc[security][str(field.name())] = field.getValueAsString()\n",
    "                            output = output.append(eltDataFrame)\n",
    "                    except Exception as e:\n",
    "                        print(e)\n",
    "            if event.eventType() == blpapi.event.Event.RESPONSE:\n",
    "                break\n",
    "        return output\n",
    "\n",
    "\n",
    "    def bdh(self, securities, fields, startdate = datetime.date(2021,1,1), enddate = datetime.date(2021,1,10), periodicity ='DAILY',\n",
    "            periodicityAdjustment = 'ACTUAL', SetFields = 'list', SetValues = 'list', OverrideFields = 'list', OverrideValues = 'list'):\n",
    "        '''\n",
    "        Emulate the BDH function found in the bloomberg addin for ecel: Historical data\n",
    "        securities: unique string identifying a unique security e.g. 'BABA US Equity' or a list of securities e.g.\n",
    "        ['BABA US Equity', 'AAPL US Equity']\n",
    "        startdate: start date in datetime format\n",
    "        enddate: end date in datetime format\n",
    "        periodicity: bloomberg parameter e.g. 'DAILY','MONTHLY'\n",
    "\n",
    "        return a dictionay, key:security, item: field data as column and date as index:\n",
    "        items = security e.g. BABA US Equity\n",
    "        Major = Dats\n",
    "        Minor = fields e.g. 'PX_LAST','EQY_WEIGHTED_AVG_PX'\n",
    "\n",
    "        example:\n",
    "        BABA = blp.bdh('BABA US Equity','PX_LAST',startdate, enddate)\n",
    "\n",
    "        '''\n",
    "        if SetValues == 'list':\n",
    "            SetValues = []\n",
    "\n",
    "        if SetFields == 'list':\n",
    "            SetFields = []\n",
    "\n",
    "        if OverrideFields == 'list':\n",
    "            OverrideFields = []\n",
    "\n",
    "        if OverrideValues == 'list':\n",
    "            OverrideValues =[]\n",
    "\n",
    "        request = self.refDataSvc.createRequest('HistoricalDataRequest')\n",
    "\n",
    "        if type(securities) == str:\n",
    "            securities = [securities]\n",
    "        for security in securities:\n",
    "            request.append('securities',security)\n",
    "\n",
    "        if type(fields) == str:\n",
    "            fields = [fields]\n",
    "        for strD in fields:\n",
    "            request.append('fields',strD)\n",
    "\n",
    "        request.set('startDate',startdate.strftime('%Y%m%d'))\n",
    "        request.set('endDate',enddate.strftime('%Y%m%d'))\n",
    "        request.set('periodicityAdjustment',periodicityAdjustment)\n",
    "        request.set('periodicitySelection',periodicity)\n",
    "\n",
    "        if len(SetFields)!= 0 & (len(SetFields) == len(SetValues)):\n",
    "            for SetField, SetValue in zip(SetFields, SetValues):\n",
    "                request.set(SetField, SetValue)\n",
    "\n",
    "        if len(OverrideFields)!= 0 & (len(OverrideFields) == len(OverrideValues)):\n",
    "            for overrideField, overrideValue in zip(OverrideFields,OverrideValues):\n",
    "                o = request.getElement('overrides').appendElement()\n",
    "                o.setElement('fieldId','overrideField')\n",
    "                o.setElement('value',overrideValue)\n",
    "\n",
    "\n",
    "        requestID = self.session.sendRequest(request)\n",
    "        panelDict = {}\n",
    "\n",
    "        while True:\n",
    "            event = self.session.nextEvent()\n",
    "            for msg in event:\n",
    "                if requestID in msg.correlationIds():\n",
    "                    try:\n",
    "                        securityData = msg.getElement(SECURITY_DATA)\n",
    "                        fieldDataArray = securityData.getElement(FIELD_DATA)\n",
    "                        fieldDataList = [fieldDataArray.getValueAsElement(i) for i in range(0, fieldDataArray.numValues())]\n",
    "                        outDates = [x.getElementAsDatetime('date') for x in fieldDataList]\n",
    "                        data = pd.DataFrame(index = outDates, columns = fields)\n",
    "                        for strD in fields:\n",
    "                            data_list = list()\n",
    "                            for fieldData in fieldDataList:\n",
    "                                try:\n",
    "                                    data_list.append(fieldData.getElementAsFloat(strD))\n",
    "                                except:\n",
    "                                    data_list.append(np.nan)\n",
    "                            data[strD] = data_list\n",
    "\n",
    "                        data.replace('#N/A History',np.nan, inplace = True)\n",
    "                        #data.index = data.index.to_datetime()\n",
    "                        data.index = pd.to_datetime(data.index)\n",
    "                        panelDict[securityData.getElementAsString(SECURITY)] = data\n",
    "                    except Exception as e:\n",
    "                        print(e)\n",
    "\n",
    "            if event.eventType() == blpapi.event.Event.RESPONSE:\n",
    "                break\n",
    "\n",
    "        #panel = pandas.Panel.fromDict(panelDict)\n",
    "        return panelDict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Master Date import\n",
    "\n",
    "file_path = 'Tickers.xlsx'\n",
    "\n",
    "ticker_df = pd.read_excel(file_path, sheet_name=None, header=None)\n",
    "\n",
    "ticker_df_sheet_names = ticker_df.keys()\n",
    "\n",
    "asian_ticker = ticker_df['Asian Equities']\n",
    "US_ticker = ticker_df['US Equities']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "asian_ticker_list = ticker_df['Asian Equities'].values.tolist()\n",
    "asian_ticker_list = [item for sublist in asian_ticker_list for item in sublist]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1186 HK Equity',\n",
       " '1898 HK Equity',\n",
       " '1088 HK Equity',\n",
       " '968 HK Equity',\n",
       " '857 HK Equity']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asian_ticker_list[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "blp = BLP()\n",
    "start_dt = datetime.date(2016,1,1)\n",
    "end_dt = datetime.date(2023,12,31)\n",
    "bdh_dict = blp.bdh(asian_ticker_list[0:5],\"PX_LAST\", start_dt ,end_dt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_df = {}\n",
    "key_df_data = {'Key': [], 'DataframeName': []}\n",
    "\n",
    "for key, value in bdh_dict.items():\n",
    "    df_name = key.replace(' ', '') + \"_df\"  \n",
    "    price_df[df_name] = pd.DataFrame(value) \n",
    "    key_df_data['Key'].append(key)\n",
    "    key_df_data['DataframeName'].append(df_name)\n",
    "\n",
    "key_df = pd.DataFrame(key_df_data)\n",
    "key_df = key_df.rename(columns={'Key': 'Ticker', 'DataframeName': 'DFName'})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Save with Pickle\n",
    "\n",
    "# with open('price_df.pkl', 'wb') as file:\n",
    "#     pickle.dump(price_df, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Open with Pickle\n",
    "\n",
    "# with open('price_df.pkl', 'rb') as file:\n",
    "#     price_df = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Daily Returns\n",
    "\n",
    "def treturn(input_df):\n",
    "    input_df['Return'] = (input_df['PX_LAST'] / input_df['PX_LAST'].shift(1)) - 1\n",
    "    input_df.fillna(0, inplace=True)\n",
    "\n",
    "    return input_df\n",
    "\n",
    "# Apply treturn function to each dataframe in price_df\n",
    "for df_name, df in price_df.items():\n",
    "    price_df[df_name] = treturn(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>DFName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1186 HK Equity</td>\n",
       "      <td>1186HKEquity_df</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1898 HK Equity</td>\n",
       "      <td>1898HKEquity_df</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1088 HK Equity</td>\n",
       "      <td>1088HKEquity_df</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>968 HK Equity</td>\n",
       "      <td>968HKEquity_df</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>857 HK Equity</td>\n",
       "      <td>857HKEquity_df</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Ticker           DFName\n",
       "0  1186 HK Equity  1186HKEquity_df\n",
       "1  1898 HK Equity  1898HKEquity_df\n",
       "2  1088 HK Equity  1088HKEquity_df\n",
       "3   968 HK Equity   968HKEquity_df\n",
       "4   857 HK Equity   857HKEquity_df"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Moving Averages \n",
    "\n",
    "moving_average_periods = [5, 20, 50, 100, 200]\n",
    "\n",
    "for df_name, df in price_df.items():\n",
    "    for period in moving_average_periods:\n",
    "        df[f'MA_{period}'] = df['PX_LAST'].rolling(window=period).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Golden and Death Cross Signals\n",
    "\n",
    "def compute_cross_signals(df):\n",
    "    # Close_5 Golden Cross/Death Cross\n",
    "    df['Close_5_GC'] = (df['PX_LAST'] > df['MA_5']) & (df['PX_LAST'].shift(1) < df['MA_5'].shift(1))\n",
    "    df['Close_5_DC'] = (df['PX_LAST'] < df['MA_5']) & (df['PX_LAST'].shift(1) > df['MA_5'].shift(1))\n",
    "\n",
    "    # 5_20 Golden Cross/Death Cross\n",
    "    df['5_20_GC'] = (df['MA_5'] > df['MA_20']) & (df['MA_5'].shift(1) < df['MA_20'].shift(1))\n",
    "    df['5_20_DC'] = (df['MA_5'] < df['MA_20']) & (df['MA_5'].shift(1) > df['MA_20'].shift(1))\n",
    "\n",
    "    # 20_100 Golden Cross/Death Cross\n",
    "    df['20_100_GC'] = (df['MA_20'] > df['MA_100']) & (df['MA_20'].shift(1) < df['MA_100'].shift(1))\n",
    "    df['20_100_DC'] = (df['MA_20'] < df['MA_100']) & (df['MA_20'].shift(1) > df['MA_100'].shift(1))\n",
    "\n",
    "    # 50_200 Golden Cross/Death Cross\n",
    "    df['50_200_GC'] = (df['MA_50'] > df['MA_200']) & (df['MA_50'].shift(1) < df['MA_200'].shift(1))\n",
    "    df['50_200_DC'] = (df['MA_50'] < df['MA_200']) & (df['MA_50'].shift(1) > df['MA_200'].shift(1))\n",
    "\n",
    "    for col_gc, col_dc in [('Close_5_GC', 'Close_5_DC'), ('5_20_GC', '5_20_DC'), ('20_100_GC', '20_100_DC'), ('50_200_GC', '50_200_DC')]:\n",
    "        df[col_gc].fillna(False, inplace=True)\n",
    "        first_gc_index = df.index[df[col_gc]].min()\n",
    "        df.loc[:first_gc_index, col_dc] = False\n",
    "\n",
    "        # Row-by-row checking and adjustment\n",
    "        for i in range(len(df)):\n",
    "            gc_count_upto_i = df.loc[:df.index[i], col_gc].sum()\n",
    "            dc_count_upto_i = df.loc[:df.index[i], col_dc].sum()\n",
    "\n",
    "            # Adjust the signals based on the counts\n",
    "            if gc_count_upto_i > dc_count_upto_i + 1:\n",
    "                df.loc[df.index[i], col_gc] = False\n",
    "            if dc_count_upto_i > gc_count_upto_i:\n",
    "                df.loc[df.index[i], col_dc] = False\n",
    "    \n",
    "    return(df)\n",
    "\n",
    "# Apply the function to each DataFrame in price_df\n",
    "# for df_name, df in price_df.items():\n",
    "#     compute_cross_signals(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Net-Position\n",
    "\n",
    "def calculate_positions(df):\n",
    "    df['Gross Long'] = 0\n",
    "    df['Gross Short'] = 0\n",
    "    df['Net Long'] = 0\n",
    "\n",
    "    previous_gross_long = 0\n",
    "    previous_gross_short = 0\n",
    "\n",
    "    for idx, row in df.iterrows():  # Use iterrows for direct row access\n",
    "        gross_long = 0\n",
    "        gross_short = 0\n",
    "\n",
    "        # Access signal values directly from row\n",
    "        for signal in df.columns:\n",
    "            if 'GC' in signal and row[signal]:\n",
    "                weight = {\n",
    "                    'Close_5_GC': 0.1,\n",
    "                    '5_20_GC': 0.2,\n",
    "                    '20_100_GC': 0.3,\n",
    "                    '50_200_GC': 0.4,\n",
    "                }[signal]  # Use direct indexing for weights\n",
    "                gross_long += weight\n",
    "\n",
    "            elif 'DC' in signal and row[signal]:\n",
    "                weight = {\n",
    "                    'Close_5_DC': 0.1,\n",
    "                    '5_20_DC': 0.2,\n",
    "                    '20_100_DC': 0.3,\n",
    "                    '50_200_DC': 0.4,\n",
    "                }[signal]\n",
    "                gross_short += weight\n",
    "\n",
    "        net_long = gross_long - gross_short\n",
    "\n",
    "        # Accumulate Gross Long\n",
    "        gross_long += previous_gross_long\n",
    "        previous_gross_long = gross_long\n",
    "\n",
    "        gross_short += previous_gross_short\n",
    "        previous_gross_short = gross_short\n",
    "\n",
    "        # Update DataFrame\n",
    "        df.loc[idx, 'Gross Long'] = gross_long\n",
    "        df.loc[idx, 'Gross Short'] = gross_short\n",
    "        df.loc[idx, 'Net Long'] = gross_long - gross_short\n",
    "\n",
    "    df['Net Long'] = df['Net Long'].shift(2)\n",
    "    df.iloc[0, df.columns.get_loc('Net Long')] = 0\n",
    "    df.iloc[1, df.columns.get_loc('Net Long')] = 0\n",
    "    df['Net Long'] = round(df['Net Long'], 2)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# for df_name, df in price_df.items():\n",
    "#     calculate_positions(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# price_df['1186HKEquity_df']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a_df = price_df['1186HKEquity_df']\n",
    "\n",
    "# close_5_gc_sum = a_df[\"Close_5_GC\"].sum()\n",
    "# close_5_dc_sum = a_df[\"Close_5_DC\"].sum()\n",
    "# five_20_gc_sum = a_df[\"5_20_GC\"].sum()\n",
    "# five_20_dc_sum = a_df[\"5_20_DC\"].sum()\n",
    "# twenty_100_gc_sum = a_df[\"20_100_GC\"].sum()\n",
    "# twenty_100_dc_sum = a_df[\"20_100_DC\"].sum()\n",
    "# fifty_200_gc_sum = a_df[\"50_200_GC\"].sum()\n",
    "# fifty_200_dc_sum = a_df[\"50_200_DC\"].sum()\n",
    "\n",
    "# # Create a dictionary to hold the results\n",
    "# data = {\n",
    "#     \"Close_5_GC\": close_5_gc_sum,\n",
    "#     \"Close_5_DC\": close_5_dc_sum,\n",
    "#     \"5_20_GC\": five_20_gc_sum,\n",
    "#     \"5_20_DC\": five_20_dc_sum,\n",
    "#     \"20_100_GC\": twenty_100_gc_sum,\n",
    "#     \"20_100_DC\": twenty_100_dc_sum,\n",
    "#     \"50_200_GC\": fifty_200_gc_sum,\n",
    "#     \"50_200_DC\": fifty_200_dc_sum\n",
    "# }\n",
    "\n",
    "# # Create the new DataFrame\n",
    "# aa_df = pd.DataFrame(data, index=[0])  # Single-row DataFrame\n",
    "# aa_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_returns(df):\n",
    "    \"\"\"Calculates daily absolute returns, portfolio value, and cumulative absolute return for a given DataFrame.\"\"\"\n",
    "    df['Daily Return'] = 1  # Set initial portfolio value as 1\n",
    "    df['Cumulative Return'] = 1\n",
    "    df['Portfolio Value'] = 1\n",
    "\n",
    "\n",
    "    df['Daily Return'] = df['Return'] * df['Net Long']\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        if i == 0:\n",
    "            pass\n",
    "        else:\n",
    "            df['Portfolio Value'].iloc[i] = df['Portfolio Value'].iloc[i - 1] + df['Daily Return'].iloc[i]\n",
    "\n",
    "    df['Cumulative Return'] = df['Portfolio Value'] - df['Net Long']\n",
    "    df['Cumulative Return'] = df['Cumulative Return'] - 1\n",
    "    return df\n",
    "\n",
    "\n",
    "# Assuming `price_df` is a dictionary of DataFrames containing price data\n",
    "# for df_name, df in price_df.items():\n",
    "#     calculate_returns(df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PX_LAST</th>\n",
       "      <th>Return</th>\n",
       "      <th>MA_5</th>\n",
       "      <th>MA_20</th>\n",
       "      <th>MA_50</th>\n",
       "      <th>MA_100</th>\n",
       "      <th>MA_200</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-04</th>\n",
       "      <td>11.46</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-05</th>\n",
       "      <td>11.34</td>\n",
       "      <td>-0.010471</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-06</th>\n",
       "      <td>11.82</td>\n",
       "      <td>0.042328</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-07</th>\n",
       "      <td>11.18</td>\n",
       "      <td>-0.054146</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-08</th>\n",
       "      <td>11.52</td>\n",
       "      <td>0.030411</td>\n",
       "      <td>11.464</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-21</th>\n",
       "      <td>25.35</td>\n",
       "      <td>0.001976</td>\n",
       "      <td>25.180</td>\n",
       "      <td>25.0500</td>\n",
       "      <td>24.717</td>\n",
       "      <td>24.1145</td>\n",
       "      <td>24.63575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-22</th>\n",
       "      <td>25.95</td>\n",
       "      <td>0.023669</td>\n",
       "      <td>25.390</td>\n",
       "      <td>25.0850</td>\n",
       "      <td>24.741</td>\n",
       "      <td>24.1410</td>\n",
       "      <td>24.64350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-27</th>\n",
       "      <td>26.30</td>\n",
       "      <td>0.013487</td>\n",
       "      <td>25.600</td>\n",
       "      <td>25.1325</td>\n",
       "      <td>24.775</td>\n",
       "      <td>24.1705</td>\n",
       "      <td>24.65275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-28</th>\n",
       "      <td>26.35</td>\n",
       "      <td>0.001901</td>\n",
       "      <td>25.850</td>\n",
       "      <td>25.1975</td>\n",
       "      <td>24.803</td>\n",
       "      <td>24.2060</td>\n",
       "      <td>24.66125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-29</th>\n",
       "      <td>26.75</td>\n",
       "      <td>0.015180</td>\n",
       "      <td>26.140</td>\n",
       "      <td>25.2700</td>\n",
       "      <td>24.843</td>\n",
       "      <td>24.2470</td>\n",
       "      <td>24.66975</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1967 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            PX_LAST    Return    MA_5    MA_20   MA_50   MA_100    MA_200\n",
       "2016-01-04    11.46  0.000000     NaN      NaN     NaN      NaN       NaN\n",
       "2016-01-05    11.34 -0.010471     NaN      NaN     NaN      NaN       NaN\n",
       "2016-01-06    11.82  0.042328     NaN      NaN     NaN      NaN       NaN\n",
       "2016-01-07    11.18 -0.054146     NaN      NaN     NaN      NaN       NaN\n",
       "2016-01-08    11.52  0.030411  11.464      NaN     NaN      NaN       NaN\n",
       "...             ...       ...     ...      ...     ...      ...       ...\n",
       "2023-12-21    25.35  0.001976  25.180  25.0500  24.717  24.1145  24.63575\n",
       "2023-12-22    25.95  0.023669  25.390  25.0850  24.741  24.1410  24.64350\n",
       "2023-12-27    26.30  0.013487  25.600  25.1325  24.775  24.1705  24.65275\n",
       "2023-12-28    26.35  0.001901  25.850  25.1975  24.803  24.2060  24.66125\n",
       "2023-12-29    26.75  0.015180  26.140  25.2700  24.843  24.2470  24.66975\n",
       "\n",
       "[1967 rows x 7 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_df['1088HKEquity_df']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Library for Dashboard\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:8050\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [29/Dec/2023 17:53:56] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [29/Dec/2023 17:53:56] \"GET /_dash-layout HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [29/Dec/2023 17:53:56] \"GET /_dash-dependencies HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [29/Dec/2023 17:53:56] \"GET /_favicon.ico?v=2.9.2 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [29/Dec/2023 17:53:56] \"GET /_dash-component-suites/dash/dcc/async-dropdown.js HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [29/Dec/2023 17:53:56] \"GET /_dash-component-suites/dash/dcc/async-datepicker.js HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [29/Dec/2023 17:53:56] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [29/Dec/2023 17:53:56] \"GET /_dash-component-suites/dash/dcc/async-graph.js HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [29/Dec/2023 17:53:56] \"GET /_dash-component-suites/dash/dcc/async-plotlyjs.js HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [29/Dec/2023 17:53:56] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [29/Dec/2023 17:53:59] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [29/Dec/2023 17:54:03] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [29/Dec/2023 17:54:04] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [29/Dec/2023 17:54:04] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [29/Dec/2023 17:54:28] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [29/Dec/2023 17:54:34] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [29/Dec/2023 17:54:34] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [29/Dec/2023 17:54:36] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [29/Dec/2023 17:54:44] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [29/Dec/2023 17:54:52] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [29/Dec/2023 17:54:52] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [29/Dec/2023 17:54:52] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [29/Dec/2023 17:55:23] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [29/Dec/2023 17:55:28] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [29/Dec/2023 17:55:30] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [29/Dec/2023 17:55:31] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [29/Dec/2023 17:55:41] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [29/Dec/2023 17:55:48] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [29/Dec/2023 17:55:49] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [29/Dec/2023 17:55:49] \"POST /_dash-update-component HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "# Create a Dash app\n",
    "app = dash.Dash()\n",
    "\n",
    "# Define app layout\n",
    "app.layout = html.Div([\n",
    "    html.H1('Stock Price Dashboard'),\n",
    "    html.Div([\n",
    "        html.Div([\n",
    "            html.Label('Select a Stock'),\n",
    "            dcc.Dropdown(\n",
    "                id='stock-dropdown',\n",
    "                options=[{'label': str(ticker), 'value': str(ticker)} for ticker in key_df['Ticker']],\n",
    "                value=str(key_df['Ticker'].iloc[0])  \n",
    "            ),\n",
    "            html.Label('Select Date Range'),\n",
    "            dcc.DatePickerRange(\n",
    "                id='date-range',\n",
    "                start_date='2016-01-01',\n",
    "                end_date='2023-12-31',\n",
    "                display_format='YYYY-MM-DD'\n",
    "            ),\n",
    "            html.Div([  \n",
    "                html.Button('6m', id='btn-6m', n_clicks=0, style={'margin-right': '5px'}),\n",
    "                html.Button('1y', id='btn-1y', n_clicks=0, style={'margin-right': '5px'}),\n",
    "                html.Button('3y', id='btn-3y', n_clicks=0, style={'margin-right': '5px'}),\n",
    "                html.Button('5y', id='btn-5y', n_clicks=0, style={'margin-right': '5px'}),\n",
    "                html.Button('All', id='btn-all', n_clicks=0)\n",
    "            ], style={'display': 'inline-block'})\n",
    "        ], style={'width': '20%', 'display': 'inline-block', 'padding': '10px', 'position': 'fixed', 'top': '10', 'left': '0', 'height': '100vh', 'overflow-y': 'auto'}),\n",
    "        html.Div([\n",
    "            dcc.Graph(id='moving-average-graph'),\n",
    "            dcc.Graph(id='MA-trading-signals'),\n",
    "            dcc.Graph(id='trade-size-graph'),\n",
    "            dcc.Graph(id='portvalue-graph'),\n",
    "        ], style={'width': '80%', 'display': 'inline-block', 'vertical-align': 'top', 'margin-left': '20%', 'padding-top': '10px'}),\n",
    "    ])\n",
    "])\n",
    "\n",
    "@app.callback(\n",
    "    dash.dependencies.Output('date-range', 'start_date'),\n",
    "    [dash.dependencies.Input('btn-6m', 'n_clicks'),\n",
    "     dash.dependencies.Input('btn-1y', 'n_clicks'),\n",
    "     dash.dependencies.Input('btn-3y', 'n_clicks'),\n",
    "     dash.dependencies.Input('btn-5y', 'n_clicks'),\n",
    "     dash.dependencies.Input('btn-all', 'n_clicks')]\n",
    ")\n",
    "def update_date_range(btn_6m, btn_1y, btn_3y, btn_5y, btn_all):\n",
    "    ctx = dash.callback_context\n",
    "\n",
    "    if ctx.triggered[0]['prop_id'].split('.')[0] == 'btn-6m':\n",
    "        return (datetime.now() - relativedelta(months=6)).strftime('%Y-%m-%d')\n",
    "    elif ctx.triggered[0]['prop_id'].split('.')[0] == 'btn-1y':\n",
    "        return (datetime.now() - relativedelta(years=1)).strftime('%Y-%m-%d')\n",
    "    elif ctx.triggered[0]['prop_id'].split('.')[0] == 'btn-3y':\n",
    "        return (datetime.now() - relativedelta(years=3)).strftime('%Y-%m-%d')\n",
    "    elif ctx.triggered[0]['prop_id'].split('.')[0] == 'btn-5y':\n",
    "        return (datetime.now() - relativedelta(years=5)).strftime('%Y-%m-%d')\n",
    "    elif ctx.triggered[0]['prop_id'].split('.')[0] == 'btn-all':\n",
    "        return '2016-01-01'  # Update this to your desired starting date for \"all\"\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    dash.dependencies.Output('moving-average-graph', 'figure'),\n",
    "    [dash.dependencies.Input('stock-dropdown', 'value'),\n",
    "     dash.dependencies.State('date-range', 'start_date'),\n",
    "     dash.dependencies.State('date-range', 'end_date')]\n",
    ")\n",
    "\n",
    "def update_moving_average_graph(selected_stock, start_date, end_date):\n",
    "    # Find the corresponding dataframe name for the selected stock\n",
    "    df_name = key_df[key_df['Ticker'] == selected_stock]['DFName'].values[0]\n",
    "    selected_stock_df = price_df[df_name]\n",
    "\n",
    "    # Get the selected stock data from the corresponding dataframe in price_df\n",
    "    selected_stock_df = selected_stock_df.loc[start_date:end_date]\n",
    "\n",
    "    fig = go.Figure()\n",
    "    # Add traces for stock price and moving averages\n",
    "    fig.add_trace(go.Scatter(x=selected_stock_df.index, y=selected_stock_df['PX_LAST'],\n",
    "                             mode='lines', name='Close', marker_color='black'))\n",
    "    fig.add_trace(go.Scatter(x=selected_stock_df.index, y=selected_stock_df['MA_5'],\n",
    "                             mode='lines', name='MA_5', marker_color='green'))\n",
    "    fig.add_trace(go.Scatter(x=selected_stock_df.index, y=selected_stock_df['MA_20'],\n",
    "                             mode='lines', name='MA_20', marker_color='yellow'))\n",
    "    fig.add_trace(go.Scatter(x=selected_stock_df.index, y=selected_stock_df['MA_50'],\n",
    "                             mode='lines', name='MA_50', marker_color='orange'))\n",
    "    fig.add_trace(go.Scatter(x=selected_stock_df.index, y=selected_stock_df['MA_100'],\n",
    "                             mode='lines', name='MA_100', marker_color='blue'))\n",
    "    fig.add_trace(go.Scatter(x=selected_stock_df.index, y=selected_stock_df['MA_200'],\n",
    "                             mode='lines', name='MA_200', marker_color='purple'))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=f'{selected_stock} Closing Price with Moving Averages',\n",
    "        xaxis_title='Date',\n",
    "        yaxis_title='Price',\n",
    "        height=1000  # Adjust height here\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "@app.callback(\n",
    "    dash.dependencies.Output('MA-trading-signals', 'figure'),\n",
    "    [dash.dependencies.Input('stock-dropdown', 'value'),\n",
    "     dash.dependencies.State('date-range', 'start_date'),\n",
    "     dash.dependencies.State('date-range', 'end_date')]\n",
    ")\n",
    "\n",
    "def update_cross_singal_graph(selected_stock, start_date, end_date):\n",
    "    # Find the corresponding dataframe name for the selected stock\n",
    "    df_name = key_df[key_df['Ticker'] == selected_stock]['DFName'].values[0]\n",
    "    selected_stock_df = price_df[df_name]\n",
    "    selected_stock_df = selected_stock_df[start_date:end_date]\n",
    "    compute_cross_signals(selected_stock_df)\n",
    "\n",
    "    # Get the selected stock data from the corresponding dataframe in price_df based on start_date and end_date\n",
    "    selected_stock_price = selected_stock_df.loc[start_date:end_date, 'PX_LAST']\n",
    "\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(x=selected_stock_price.index, y=selected_stock_price,\n",
    "                             mode='lines', name='Close', marker_color='black'))\n",
    "    fig.update_layout(\n",
    "        title=f'{selected_stock} Closing Price',\n",
    "        xaxis_title='Date',\n",
    "        yaxis_title='Price',\n",
    "        height=1000\n",
    "    )\n",
    "\n",
    "    # Adding trading signals for Golden Cross (GC)\n",
    "    for col, color in [('Close_5_GC', 'black'), ('5_20_GC', 'green'), ('20_100_GC', 'yellow'), ('50_200_GC', 'orange')]:\n",
    "        crosses = selected_stock_df[(selected_stock_df[col]) & (selected_stock_df.index >= start_date) & (selected_stock_df.index <= end_date)].index\n",
    "        dates = crosses  # Selecting dates for x-axis\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=dates, y=selected_stock_df.loc[crosses, 'PX_LAST'], mode='markers', \n",
    "                       marker=dict(color=color, symbol='triangle-up', size=10), name=col)\n",
    "        )\n",
    "\n",
    "    # Adding trading signals for Death Cross (DC)\n",
    "    for col, color in [('Close_5_DC', 'black'), ('5_20_DC', 'green'), ('20_100_DC', 'yellow'), ('50_200_DC', 'orange')]:\n",
    "        crosses = selected_stock_df[(selected_stock_df[col]) & (selected_stock_df.index >= start_date) & (selected_stock_df.index <= end_date)].index\n",
    "        dates = crosses  # Selecting dates for x-axis\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=dates, y=selected_stock_df.loc[crosses, 'PX_LAST'], mode='markers', \n",
    "                       marker=dict(color=color, symbol='triangle-down', size=10), name=col)\n",
    "        )\n",
    "\n",
    "    return fig\n",
    "\n",
    "@app.callback(\n",
    "    dash.dependencies.Output('trade-size-graph', 'figure'),\n",
    "    [dash.dependencies.Input('stock-dropdown', 'value'),\n",
    "     dash.dependencies.State('date-range', 'start_date'),\n",
    "     dash.dependencies.State('date-range', 'end_date')]\n",
    ")\n",
    "def update_trade_size(selected_stock, start_date, end_date):\n",
    "    # Find the corresponding dataframe name for the selected stock\n",
    "    df_name = key_df[key_df['Ticker'] == selected_stock]['DFName'].values[0]\n",
    "    selected_stock_df = price_df[df_name]\n",
    "    selected_stock_df = selected_stock_df.loc[start_date:end_date]\n",
    "    compute_cross_signals(selected_stock_df)\n",
    "    calculate_positions(selected_stock_df)\n",
    "\n",
    "    # Update positions using the calculate_positions function\n",
    "    total_days = len(selected_stock_df)\n",
    "    avg_net_long = selected_stock_df['Net Long'].mean()\n",
    "    trading_days = (selected_stock_df['Net Long'] > 0.01).sum()\n",
    "    percentage_non_zero_days = (trading_days / total_days) * 100\n",
    "\n",
    "    # Create figure for trade size graph based on updated positions\n",
    "    trade_size_fig = go.Figure()\n",
    "\n",
    "    # Add trace for net long position to the trade size graph\n",
    "    trade_size_fig.add_trace(go.Scatter(x=selected_stock_df.index,\n",
    "                                        y=selected_stock_df['Net Long'],\n",
    "                                        mode='lines',\n",
    "                                        name='Net Long Position'))\n",
    "\n",
    "    # Extract the last net long value for annotation\n",
    "    last_net_long = round(selected_stock_df['Net Long'].iloc[-1], 2)\n",
    "\n",
    "    # Update the layout for trade size graph and add annotation\n",
    "    trade_size_fig.update_layout(\n",
    "        title=f'{selected_stock} Net Long Position',\n",
    "        xaxis_title='Date',\n",
    "        yaxis_title='Net Long Position',\n",
    "        annotations=[\n",
    "            dict(\n",
    "                xref='paper',\n",
    "                yref='paper',\n",
    "                x=1,\n",
    "                y=1,\n",
    "                text=f'Current Net-Long: {last_net_long}<br>'\n",
    "                     f'Average Net-Long: {round(avg_net_long, 2)}<br>'\n",
    "                     f'Number of days: {round(total_days, 2)}<br>'\n",
    "                     f'Number of trading days: {round(trading_days, 2)}<br>'\n",
    "                     f'Trading days %: {round(percentage_non_zero_days, 2)}',\n",
    "                showarrow=False,\n",
    "                font=dict(size=12)\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return trade_size_fig\n",
    "\n",
    "@app.callback(\n",
    "    dash.dependencies.Output('portvalue-graph', 'figure'),\n",
    "    [dash.dependencies.Input('stock-dropdown', 'value'),\n",
    "     dash.dependencies.State('date-range', 'start_date'),\n",
    "     dash.dependencies.State('date-range', 'end_date')]\n",
    ")\n",
    "def update_cumret_graph(selected_stock, start_date, end_date):\n",
    "    # Find the corresponding dataframe name for the selected stock\n",
    "    df_name = key_df[key_df['Ticker'] == selected_stock]['DFName'].values[0]\n",
    "    selected_stock_df = price_df[df_name]\n",
    "    selected_stock_df = selected_stock_df.loc[start_date:end_date]\n",
    "    compute_cross_signals(selected_stock_df)\n",
    "    calculate_positions(selected_stock_df)\n",
    "    calculate_returns(selected_stock_df)\n",
    "\n",
    "    \n",
    "    # Calculate statistics - Portfolio\n",
    "    positive_returns = selected_stock_df[selected_stock_df['Daily Return'] > 0]['Daily Return']\n",
    "    negative_returns = selected_stock_df[selected_stock_df['Daily Return'] < 0]['Daily Return']\n",
    "    trading_days = (selected_stock_df['Net Long'] > 0.05).sum()\n",
    "    num_positive_days = positive_returns.count()\n",
    "    percentage_positive_days = (num_positive_days / trading_days) * 100\n",
    "    avg_positive_return = positive_returns.mean() if num_positive_days > 0 else 0\n",
    "    avg_negative_return = negative_returns.mean() if negative_returns.count() > 0 else 0\n",
    "    avg_negative_return = abs(avg_negative_return)\n",
    "    skew = avg_positive_return / avg_negative_return if avg_negative_return != 0 else 0\n",
    "\n",
    "    # Calculate statistics - Benchmark\n",
    "    bm_positive_returns = selected_stock_df[selected_stock_df['Return'] > 0]['Return']\n",
    "    bm_negative_returns = selected_stock_df[selected_stock_df['Return'] < 0]['Return']\n",
    "    bm_num_positive_days = bm_positive_returns.count()\n",
    "    bm_trading_days = len(selected_stock_df)\n",
    "    bm_percentage_positive_days = (bm_num_positive_days / bm_trading_days) * 100\n",
    "    bm_avg_positive_return = bm_positive_returns.mean() if num_positive_days > 0 else 0\n",
    "    bm_avg_negative_return = bm_negative_returns.mean() if negative_returns.count() > 0 else 0\n",
    "    bm_avg_negative_return = abs(bm_avg_negative_return)\n",
    "    bm_skew = bm_avg_positive_return / bm_avg_negative_return if bm_avg_negative_return != 0 else 0\n",
    "\n",
    "    # Portfolio Value\n",
    "    selected_cumulative_returns = selected_stock_df.loc[start_date:end_date, 'Portfolio Value']\n",
    "    first_cumulative_return = selected_cumulative_returns.iloc[0]\n",
    "    selected_cumulative_returns = selected_cumulative_returns / first_cumulative_return\n",
    "\n",
    "    # Portfolio Value for the benchmark\n",
    "    benchmark_cumulative_returns = selected_stock_df['PX_LAST'] / selected_stock_df['PX_LAST'].iloc[0]\n",
    "\n",
    "    # Create a graph for cumulative returns\n",
    "    fig_cumulative_returns = go.Figure()\n",
    "    fig_cumulative_returns.add_trace(go.Scatter(x=selected_cumulative_returns.index,\n",
    "                                                y=selected_cumulative_returns,\n",
    "                                                mode='lines',\n",
    "                                                name='Portfolio Value',\n",
    "                                                marker_color='blue'))\n",
    "    \n",
    "    fig_cumulative_returns.add_trace(go.Scatter(x=benchmark_cumulative_returns.index,\n",
    "                                                y=benchmark_cumulative_returns,\n",
    "                                                mode='lines',\n",
    "                                                name='Benchmark',\n",
    "                                                marker_color='green'))\n",
    "    \n",
    "    fig_cumulative_returns.update_layout(\n",
    "        title=f'{selected_stock} Portfolio Value',\n",
    "        xaxis_title='Date',\n",
    "        yaxis_title='Portfolio Value',\n",
    "        height=1000\n",
    "    )\n",
    "    \n",
    "    fig_cumulative_returns.add_annotation(\n",
    "        xref='paper',\n",
    "        yref='paper',\n",
    "        x=1,\n",
    "        y=1,\n",
    "        text=f'Total Trading Days: {trading_days}<br>'\n",
    "             f'Number of Positive Return Days: {num_positive_days}<br>'\n",
    "             f'% of Positive Return Days: {round(percentage_positive_days, 2)}%<br>'\n",
    "             f'Average Positive Return: {round(avg_positive_return, 4)}<br>'\n",
    "             f'Average Negative Return: {round(avg_negative_return, 4)}<br>'\n",
    "             f'Skew: {round(skew, 4)}<br>',\n",
    "            #  f'Benchmark - Total Trading Days: {bm_trading_days}<br>'\n",
    "            #  f'Benchmark - Number of Positive Return Days: {bm_num_positive_days}<br>'\n",
    "            #  f'Benchmark - % of Positive Return Days: {round(bm_percentage_positive_days, 2)}%<br>'\n",
    "            #  f'Benchmark - Average Positive Return: {round(bm_avg_positive_return, 4)}<br>'\n",
    "            #  f'Benchmark - Average Negative Return: {round(bm_avg_negative_return, 4)}<br>'\n",
    "            #  f'Benchmark - Skew: {round(bm_skew, 4)}',\n",
    "        showarrow=False,\n",
    "        font=dict(size=12)\n",
    "    )\n",
    "\n",
    "    fig_cumulative_returns.add_annotation(\n",
    "        xref='paper',\n",
    "        yref='paper',\n",
    "        x=0,\n",
    "        y=1,\n",
    "        text=f'Benchmark - Total Trading Days: {bm_trading_days}<br>'\n",
    "             f'Benchmark - Number of Positive Return Days: {bm_num_positive_days}<br>'\n",
    "             f'Benchmark - % of Positive Return Days: {round(bm_percentage_positive_days, 2)}%<br>'\n",
    "             f'Benchmark - Average Positive Return: {round(bm_avg_positive_return, 4)}<br>'\n",
    "             f'Benchmark - Average Negative Return: {round(bm_avg_negative_return, 4)}<br>'\n",
    "             f'Benchmark - Skew: {round(bm_skew, 4)}',\n",
    "        showarrow=False,\n",
    "        font=dict(size=12)\n",
    "    )\n",
    "\n",
    "    return fig_cumulative_returns\n",
    "\n",
    "app.run_server()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_return_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions = {\n",
    "    'Close_5_GC': 0,\n",
    "    '5_20_GC': 0,\n",
    "    '20_50_GC': 0,\n",
    "    '50_100_GC': 0,\n",
    "    '100_200_GC': 0,\n",
    "}\n",
    "\n",
    "net_long_position = 0\n",
    "\n",
    "# Simulated strategy implementation\n",
    "for index, row in df.iterrows():\n",
    "    for signal in df.columns:\n",
    "        if 'GC' in signal and row[signal] == 1:  # Golden Cross signal\n",
    "            weight = {\n",
    "                'Close_5_GC': 0.05,\n",
    "                '5_20_GC': 0.075,\n",
    "                '20_50_GC': 0.125,\n",
    "                '50_100_GC': 0.25,\n",
    "                '100_200_GC': .5,\n",
    "            }[signal]\n",
    "            positions[signal] += weight\n",
    "            net_long_position += weight\n",
    "\n",
    "        elif 'DC' in signal and row[signal] == 1:  # Death Cross signal\n",
    "            weight = {\n",
    "                'Close_5_DC': 0.05,\n",
    "                '5_20_DC': 0.075,\n",
    "                '20_50_DC': 0.125,\n",
    "                '50_100_DC': 0.25,\n",
    "                '100_200_DC': .5,\n",
    "            }[signal]\n",
    "            reduction = weight + net_long_position\n",
    "            positions[signal.replace('DC', 'GC')] -= reduction\n",
    "            net_long_position -= reduction\n",
    "\n",
    "# Accumulate data in a list\n",
    "data = [{'Signal': signal, 'Position': position} for signal, position in positions.items()]\n",
    "data.append({'Signal': 'Net Long Position', 'Position': net_long_position})\n",
    "\n",
    "# Create DataFrame from the accumulated data\n",
    "TS_Position_Size = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TS_Position_Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=1, cols=1, shared_xaxes=True)\n",
    "\n",
    "# Add trace for Close prices\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=df['Date'], y=df['Close'], mode='lines', name='Close', marker_color='black'),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# Update x-axis options for range selection\n",
    "fig.update_xaxes(\n",
    "    rangeslider_visible=False,\n",
    "    rangeselector=dict(\n",
    "        buttons=list([\n",
    "            dict(count=6, label=\"6m\", step=\"month\", stepmode=\"backward\"),\n",
    "            dict(count=1, label=\"1y\", step=\"year\", stepmode=\"backward\"),\n",
    "            dict(count=3, label=\"3y\", step=\"year\", stepmode=\"backward\"),\n",
    "            dict(count=5, label=\"5y\", step=\"year\", stepmode=\"backward\"),\n",
    "            dict(step=\"all\")\n",
    "        ])\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# # Add trace for Net Long positions\n",
    "net_long_changes = df[df['Net Long'].diff() != 0]\n",
    "# fig.add_trace(\n",
    "#         go.Scatter(x=net_long_changes['Date'], y=net_long_changes['Close'],\n",
    "#                mode='text',\n",
    "#                text=[f\"{round(val, 2)}\" for val in net_long_changes['Net Long']],\n",
    "#                textposition=\"top left\",\n",
    "#                showlegend=False\n",
    "#         ),\n",
    "#     row=1, col=1\n",
    "# )\n",
    "\n",
    "net_long_changes['Date'] = pd.to_datetime(net_long_changes['Date'])\n",
    "net_long_changes = net_long_changes.groupby(net_long_changes['Date'].dt.to_period(\"M\")).first().reset_index(drop=True)\n",
    "\n",
    "# Add trace for Net Long positions (once a month)\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=net_long_changes['Date'],\n",
    "        y=net_long_changes['Close'],\n",
    "        mode='text',\n",
    "        text=[f\"{round(val, 2)}\" for val in net_long_changes['Net Long']],\n",
    "        textposition=\"top left\",\n",
    "        showlegend=False\n",
    "    ),\n",
    "    row=1,\n",
    "    col=1\n",
    ")\n",
    "\n",
    "# Update layout and display\n",
    "fig.update_layout(\n",
    "    title='Close and Net Long Position Changes',\n",
    "    hovermode='x unified',\n",
    "    height=1000,\n",
    "    yaxis=dict(title='Price'),\n",
    "    showlegend=True\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FUNCTION: Strategy Return\n",
    "\n",
    "def strat_return(input_df, Net_Position_Col ,port_value, strat_return, strat_abs_return, ts_type):\n",
    "    \n",
    "    #Net Position \n",
    "    input_df[Net_Position_Col]\n",
    "   \n",
    "    #Strategy Value (\"xxx SValue\")\n",
    "    input_df[port_value] = 0\n",
    "    \n",
    "    #Strategy Return (\"xxx SReturn\")\n",
    "    input_df[strat_return] = 0\n",
    "\n",
    "    #Absolute Return ('xxx AbsReturn)\n",
    "    input_df[strat_abs_return] = 0\n",
    "\n",
    "    \n",
    "    for i in range(len(input_df)):\n",
    "\n",
    "        #Daily Return of the Strategy\n",
    "        if input_df.at[i, Net_Position_Col ] > 0:\n",
    "            input_df.at[i, strat_return] = input_df.at[i, 'Return']\n",
    "\n",
    "        if ts_type == 'Short':\n",
    "            input_df.at[i, strat_return] = input_df.at[i, strat_return] * -1 \n",
    "                \n",
    "        #Daily Portfolio Value\n",
    "        if input_df.at[i, Net_Position_Col ] > 0:\n",
    "            if i == 0:\n",
    "                if input_df.at[i, Net_Position_Col ] == 1:\n",
    "                    input_df.at[i, port_value] = 1\n",
    "                else:\n",
    "                    pass\n",
    "            elif input_df.at[i-1, port_value] == 0:\n",
    "                input_df.at[i, port_value] = 1 * (1+ input_df.at[i, strat_return])\n",
    "            else:\n",
    "                new_inv = input_df.at[i, Net_Position_Col ] - input_df.at[i-1, Net_Position_Col ] \n",
    "                input_df.at[i, port_value] = (input_df.at[i-1, port_value]+ new_inv) * (1+ input_df.at[i, strat_return])\n",
    "\n",
    "        #Daily Absoulte Return\n",
    "        input_df.at[i, strat_abs_return] = input_df.at[i, port_value] - input_df.at[i, Net_Position_Col]\n",
    "    \n",
    "    input_df.fillna(0, inplace = True)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strat_return(df, 'Net Long', 'TS SValue', 'TS SReturn', 'TS AbsReturn', \"Long\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=1, cols=1, shared_xaxes=True)\n",
    "\n",
    "# Add trace for Close prices\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=df['Date'], y=df['Net Long'], mode='lines', name='Close', marker_color='black'),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# Update x-axis options for range selection\n",
    "fig.update_xaxes(\n",
    "    rangeslider_visible=False,\n",
    "    rangeselector=dict(\n",
    "        buttons=list([\n",
    "            dict(count=6, label=\"6m\", step=\"month\", stepmode=\"backward\"),\n",
    "            dict(count=1, label=\"1y\", step=\"year\", stepmode=\"backward\"),\n",
    "            dict(count=3, label=\"3y\", step=\"year\", stepmode=\"backward\"),\n",
    "            dict(count=5, label=\"5y\", step=\"year\", stepmode=\"backward\"),\n",
    "            dict(step=\"all\")\n",
    "        ])\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# Update layout and display\n",
    "fig.update_layout(\n",
    "    title='Net Long / Sizing',\n",
    "    hovermode='x unified',\n",
    "    height=1000,\n",
    "    yaxis=dict(title='Trade Size'),\n",
    "    showlegend=True\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FUNCTION: Compute the number of days each trade takes to become positive. \n",
    "\n",
    "\n",
    "def trade_days(input_df, strat_inv_column):\n",
    "    #Dataframe to collect the number of days each trade took to become positive\n",
    "    data = {'Trade': [0, 0],'Trade Date': [0, 0],'Purchase Price': [0, 0], 'Positive Close': [0, 0], 'Positive Date': [0,0], 'Days to Positive': [0,0]}\n",
    "    trade_df = pd.DataFrame(data)\n",
    "\n",
    "    #Initialize Values\n",
    "    new_trade = 0\n",
    "    trade_days = 0\n",
    "    positive_trade = 0\n",
    "    trade_number = 0\n",
    "        \n",
    "    for i in range(len(input_df)):\n",
    "        \n",
    "        #Register a new trade\n",
    "        if i == 0:\n",
    "            if input_df.at[i, strat_inv_column] == 1:\n",
    "               new_trade = 1\n",
    "               trade_number += 1\n",
    "        else:\n",
    "            if input_df.at[i, strat_inv_column] - input_df.at[i-1, strat_inv_column] == 1:\n",
    "                new_trade = 1\n",
    "                trade_number += 1\n",
    "        \n",
    "        # If there is a new trade, find the days it takes to reach positive value\n",
    "        if new_trade == 1:\n",
    "            purchase_price = input_df.at[i, 'Close']\n",
    "        \n",
    "            for a in range(len(input_df)-i):\n",
    "                \n",
    "                trade_days += 1\n",
    "\n",
    "                if input_df.at[a+i, 'Close'] > purchase_price:\n",
    "                    positive_trade = 1\n",
    "                    trade_df.at[trade_number, 'Trade'] = trade_number\n",
    "                    trade_df.at[trade_number, 'Trade Date'] = i\n",
    "                    trade_df.at[trade_number, 'Purchase Price'] = purchase_price\n",
    "                    trade_df.at[trade_number, 'Positive Close'] = input_df.at[a+i, 'Close']\n",
    "                    trade_df.at[trade_number, 'Positive Date'] = a+i\n",
    "                    trade_df.at[trade_number, 'Days to Positive'] = trade_days-1\n",
    "                    \n",
    "                    #Reset values\n",
    "                    new_trade = 0\n",
    "                    positive_trade = 0\n",
    "                    trade_days = 0\n",
    "                    break\n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "            \n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    trade_df = trade_df.iloc[1:]\n",
    "    \n",
    "    return(trade_df)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TS_trade_df = trade_days(df, 'Net Long')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TS_trade_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'Date' is a datetime column in your DataFrame\n",
    "plt.figure(figsize=(25, 10))\n",
    "\n",
    "# Plot 'TS PValue'\n",
    "plt.plot(df['Date'], df['TS AbsReturn'], label='Trading Strategy')\n",
    "\n",
    "\n",
    "# Plot 'CReturns'\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Absolute Return')\n",
    "plt.title('Absolute Return')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "x_indices = np.arange(0, len(df), 30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tstrat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
